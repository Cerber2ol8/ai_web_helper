{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84ab0f44",
   "metadata": {},
   "source": [
    "## Step 1. 安装所需依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66243526",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e646d2",
   "metadata": {},
   "source": [
    "## Step 2. 从ModelScope下载模型\n",
    "\n",
    "选取的模型为 Qwen3-30B-A3B-Instruct-2507"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ae5e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "!modelscope download --model Qwen/Qwen3-30B-A3B-Instruct-2507  --local_dir ./Qwen/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d360671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试模型推理\n",
    "import os\n",
    "# 删除:from modelscope.pipelines import pipeline\n",
    "# 删除:from modelscope.utils.constant import Tasks\n",
    "\n",
    "# 添加vLLM相关导入\n",
    "from vllm import LLM\n",
    "from vllm.sampling_params import SamplingParams\n",
    "\n",
    "# 设置模型路径（请根据实际下载路径进行调整）\n",
    "model_path = './Qwen/Qwen3-30B-A3B-Instruct-2507'\n",
    "\n",
    "# 检查模型路径是否存在\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(f\"模型路径不存在: {model_path}\")\n",
    "\n",
    "# 创建vLLM模型实例\n",
    "llm = LLM(\n",
    "    model=model_path,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# 启动推理服务\n",
    "def infer(text):\n",
    "    # 使用vLLM进行推理\n",
    "    sampling_params = SamplingParams(temperature=0.7, max_tokens=512)\n",
    "    outputs = llm.generate([text], sampling_params)\n",
    "    return outputs[0].outputs[0].text\n",
    "\n",
    "# 测试模型推理\n",
    "if __name__ == '__main__':\n",
    "    test_input = \"你好，世界！\"\n",
    "    output = infer(test_input)\n",
    "    print(\"模型输出:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf4934a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 销毁模型\n",
    "import gc\n",
    "import torch\n",
    "del llm\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb29b169",
   "metadata": {},
   "source": [
    "## Step 3. 部署模型为推理服务\n",
    "\n",
    "这里使用Fast API方式部署，持久化推荐vllm部署"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b194f3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# 加载模型服务\n",
    "!python server.py --model './Qwen/Qwen3-30B-A3B-Instruct-2507' --host 0.0.0.0 --port 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df670e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试API端点\n",
    "def test_api_endpoint(endpoint=\"/v1/models\", host=\"127.0.0.1\", port=8000, token=None):\n",
    "    import requests\n",
    "    url = f\"http://{host}:{port}{endpoint}\"\n",
    "    print(f\"测试API端点: {url}\")\n",
    "    headers = {}\n",
    "    if token:\n",
    "        headers[\"Authorization\"] = f\"Bearer {token}\"\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        print(f\"响应状态码: {response.status_code}\")\n",
    "        print(f\"响应内容: {response.json()}\")\n",
    "        return response.json()\n",
    "    except Exception as e:\n",
    "        print(f\"测试API端点时出错: {str(e)}\")\n",
    "        return None\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "token = os.getenv(\"API_KEY\")\n",
    "test_api_endpoint(token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9bc22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试客户端测试推理（可忽略）\n",
    "%TOKEN=\"sk-1234567890\"\n",
    "!python client.py --host 127.0.0.1 --port 8000 --token $TOKEN --model Qwen3-30B-A3B-Instruct-2507 --prompt \"你好，超算互联网！\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c04355",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}



